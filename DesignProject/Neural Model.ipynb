{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DQPjajUrJLu4",
    "outputId": "8e49c21c-b574-497c-f403-2cc0ff2f9dd5"
   },
   "outputs": [],
   "source": [
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fiVBcHvSLbbv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class LOLDataset(Dataset):\n",
    "    def __init__(self, low_dir, high_dir, transform=None):\n",
    "        self.low_dir = low_dir\n",
    "        self.high_dir = high_dir\n",
    "        self.low_images = sorted(os.listdir(low_dir))\n",
    "        self.high_images = sorted(os.listdir(high_dir))\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.low_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        low_path = os.path.join(self.low_dir, self.low_images[idx])\n",
    "        high_path = os.path.join(self.high_dir, self.high_images[idx])\n",
    "\n",
    "        low_img = cv2.imread(low_path, cv2.IMREAD_GRAYSCALE)\n",
    "        high_img = cv2.imread(high_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if low_img is None or high_img is None:\n",
    "            raise ValueError(f\"Could not read image: {low_path} or {high_path}\")\n",
    "\n",
    "\n",
    "        low_img = transforms.ToPILImage()(low_img)\n",
    "        high_img = transforms.ToPILImage()(high_img)\n",
    "\n",
    "        if self.transform:\n",
    "            low_img = self.transform(low_img)\n",
    "            high_img = self.transform(high_img)\n",
    "\n",
    "        return low_img, high_img\n",
    "\n",
    "class PreCEModule(nn.Module):\n",
    "    def forward(self, x):\n",
    "        eps = 1e-6\n",
    "        x_min = x.min()\n",
    "        x_max = x.max()\n",
    "        return (x - x_min) / (x_max - x_min + eps)\n",
    "\n",
    "class GlobalEnhanceNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 16, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(16, 4, 3, padding=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        v = torch.cat([\n",
    "            torch.ones_like(x),\n",
    "            x,\n",
    "            x**2,\n",
    "            x**3\n",
    "        ], dim=1)\n",
    "\n",
    "\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        theta_g = self.conv4(x)\n",
    "\n",
    "\n",
    "        b, _, h, w = x.shape\n",
    "        theta_g = theta_g.view(b, 4, 1, h, w)\n",
    "        v = v.view(b, 4, 1, h, w)\n",
    "        x_g = (theta_g * v).sum(dim=1, keepdim=True)\n",
    "        return x_g\n",
    "\n",
    "class LocalEnhanceNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 16, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(16, 4, 3, padding=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        v = torch.cat([\n",
    "            torch.ones_like(x),\n",
    "            x,\n",
    "            x**2,\n",
    "            x**3\n",
    "        ], dim=1)\n",
    "\n",
    "\n",
    "        x = self.relu(self.conv1(v))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        theta_l = self.conv4(x)\n",
    "\n",
    "\n",
    "        b, _, h, w = x.shape\n",
    "        theta_l = theta_l.view(b, 4, 1, h, w)\n",
    "        v = v.view(b, 4, 1, h, w)\n",
    "        x_l = (theta_l * v).sum(dim=1, keepdim=True)\n",
    "        return x_l\n",
    "\n",
    "class GLCENetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pre_ce = PreCEModule()\n",
    "        self.global_net = GlobalEnhanceNet()\n",
    "        self.local_net = LocalEnhanceNet()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_std = self.pre_ce(x)\n",
    "        x_g = self.global_net(x_std)\n",
    "        x_l = self.local_net(x_std)\n",
    "\n",
    "        enhanced = x_std + x_l + x_g\n",
    "        return torch.clamp(enhanced, 0, 1)\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def histogram_loss(self, pred, target, bins=256):\n",
    "        def compute_histogram(tensor):\n",
    "            eps = 1e-8\n",
    "            tensor = torch.clamp(tensor, 0, 1)\n",
    "            hist = torch.histc(tensor.float(), bins=bins, min=0, max=1)\n",
    "            return hist / (hist.sum() + eps)\n",
    "\n",
    "        pred_hist = compute_histogram(pred)\n",
    "        target_hist = compute_histogram(target)\n",
    "        return F.l1_loss(pred_hist, target_hist)\n",
    "\n",
    "    def gradient_loss(self, pred, target):\n",
    "        def get_gradient(x):\n",
    "\n",
    "            gradient_x = F.pad(x[:, :, :, 1:] - x[:, :, :, :-1], (0, 1, 0, 0))\n",
    "            gradient_y = F.pad(x[:, :, 1:, :] - x[:, :, :-1, :], (0, 0, 0, 1))\n",
    "            return gradient_x, gradient_y\n",
    "\n",
    "        pred_gradient_x, pred_gradient_y = get_gradient(pred)\n",
    "        target_gradient_x, target_gradient_y = get_gradient(target)\n",
    "\n",
    "        gradient_loss = F.l1_loss(pred_gradient_x, target_gradient_x) + \\\n",
    "                       F.l1_loss(pred_gradient_y, target_gradient_y)\n",
    "        return gradient_loss\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "\n",
    "        if pred.size() != target.size():\n",
    "            target = target.expand_as(pred)\n",
    "\n",
    "\n",
    "        α1, α2, α3 = 1.0, 0.2, 0.5\n",
    "\n",
    "        mse_loss = self.mse(pred, target)\n",
    "        hist_loss = self.histogram_loss(pred, target)\n",
    "        grad_loss = self.gradient_loss(pred, target)\n",
    "\n",
    "        total_loss = α1 * mse_loss + α2 * hist_loss + α3 * grad_loss\n",
    "        return total_loss\n",
    "\n",
    "def train_model(model, train_loader, num_epochs=240, learning_rate=1e-4):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = CustomLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        batch_count = 0\n",
    "\n",
    "        for low_img, high_img in train_loader:\n",
    "            low_img = low_img.to(device)\n",
    "            high_img = high_img.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            enhanced_img = model(low_img)\n",
    "            loss = criterion(enhanced_img, high_img)\n",
    "\n",
    "            if not torch.isnan(loss) and not torch.isinf(loss):\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                batch_count += 1\n",
    "\n",
    "        if batch_count > 0:\n",
    "            avg_loss = epoch_loss / batch_count\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "            scheduler.step(avg_loss)\n",
    "\n",
    "            if avg_loss < best_loss:\n",
    "                best_loss = avg_loss\n",
    "                torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "def test_model(model, test_image_path, output_path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "\n",
    "    img = cv2.imread(test_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        enhanced = model(img)\n",
    "\n",
    "\n",
    "    enhanced = enhanced.cpu().squeeze().numpy()\n",
    "    enhanced = (enhanced * 255).clip(0, 255).astype(np.uint8)\n",
    "    cv2.imwrite(output_path, enhanced)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(42)\n",
    "\n",
    "    low_dir = 'data/low'\n",
    "    high_dir = 'data/high'\n",
    "    dataset = LOLDataset(low_dir, high_dir)\n",
    "    train_loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "    model = GLCENetwork()\n",
    "    train_model(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AYPLMz0kUkxD",
    "outputId": "c120406f-fa73-48bd-875d-7b0433691fb7"
   },
   "outputs": [],
   "source": [
    "!unzip test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z5j3N7wCUG3e",
    "outputId": "7a737620-318a-4483-c2d0-67541cd7a1fc"
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_image_path, output_path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    img = cv2.imread(test_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Image at {test_image_path} could not be loaded\")\n",
    "\n",
    "    img = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        enhanced = model(img)\n",
    "\n",
    "    enhanced = enhanced.cpu().squeeze().numpy()\n",
    "    enhanced = (enhanced * 255).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "    output_path_with_extension = output_path + '.png'\n",
    "    cv2.imwrite(output_path_with_extension, enhanced)\n",
    "    print(f\"Enhanced image saved to {output_path_with_extension}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  test_model(model, 'test/one.jpg', 'test/enhnone')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MV4Eb-n7ZHJ7"
   },
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model.state_dict(), 'model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxiNCOOJZe1g"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = GLCENetwork()\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model.eval()\n",
    "test_model(model, '7.1.03.tiff', 'test/enhancedtank')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
